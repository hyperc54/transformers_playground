{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64445f43-7bac-4433-a619-4e1849ac662a",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This notebook is part of a mini-series that aims to build a simple RAG system for learning purposes.\n",
    "\n",
    "This notebook is a bit independent from others as it will just highlight some experiments done with\n",
    "different indexing methods.\n",
    "\n",
    "This notebook assumes:\n",
    "- we have a dataset available of chunks of text data to index **with appropriate embeddings** `chunk_id (int) | text_chunk (str) | embedding (tensor(N))`.\n",
    "\n",
    "We'd like now to implement obtain nearest-neighbour search index for document retrieval.\n",
    "\n",
    "Plan:\n",
    "- The first section implements a simple flat kNN solution and observes its speed\n",
    "- The second section replaces the dummy approach with 2 more sophisticated approaches (Inverted file index, HNSW index)\n",
    "- The third section shows how to evaluate approximate nearest neighbours search solutions independently of the questions datasets\n",
    "- There could have been a fourth section which evaluates our end-to-end retrieval flow (question -> embedding -> document retrieval -> is the document relevant?), but this has been done in the [Step 1] with a simple Flat Index solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "73ce77f2-c840-455c-800a-54d5346dfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# This library contains an implementation for all the index retrieval algorithms we'd like to try\n",
    "import faiss\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "LOCAL_DATASET_FOLDER = \"local_datasets\"\n",
    "\n",
    "# The number of searches that we'll time to measure speed improvements\n",
    "N_SEARCH_TIMEIT = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214ab6d-bd7b-46d8-9e06-78dfa139ca0d",
   "metadata": {},
   "source": [
    "# Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d741bd4-9b28-475b-bac1-196db1637c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_DATASET_NAME = \"wiki-data-chunked-recursive-CS300with_simple_embeddings\"\n",
    "\n",
    "corpus_dataset = load_from_disk(\n",
    "    os.path.join(LOCAL_DATASET_FOLDER, CORPUS_DATASET_NAME)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd5278c-be0b-4dfa-999d-2e1b9f8b5d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'original_id', 'text_chunk', 'embedding'],\n",
       "    num_rows: 271938\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2897b2cf-af50-4e01-9094-7366d5e5a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some common parameters\n",
    "dim = len(corpus_dataset[0][\"embedding\"]) # dimension\n",
    "k = 5 # number of neighbours to retrieve for each query\n",
    "\n",
    "# a random vector to query for testing\n",
    "INDEX_TO_RETRIEVE_SINGLE_VECTOR = 53 #random\n",
    "vector_in_index = np.array(\n",
    "    [corpus_dataset[INDEX_TO_RETRIEVE_SINGLE_VECTOR][\"embedding\"]]\n",
    ")\n",
    "eps = 1e-2\n",
    "vector_in_index_with_noise = vector_in_index + eps * np.random.random(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d34a74-4922-4a0a-a6f7-fd4d31bf4a2f",
   "metadata": {},
   "source": [
    "# Section 1: Dummy Flat search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f123a0fb-b4c7-4fc2-ac44-6e61d2bb7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use InnerProduct directly as our embeddings are already normalised\n",
    "# Initialise the index, the FAISS package makes it super easy\n",
    "flat_index = faiss.IndexFlatIP(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8f7473-f9f3-4b15-a64a-a23a251279b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luckily we can all load it at once here\n",
    "all_vectors = np.array(corpus_dataset[\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d0ae44-467a-4c4e-8306-7f0f581c6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And add everything one shot\n",
    "flat_index.add(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "275f3a02-f4e3-4293-ae7c-0826bf86a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999998  0.67321146 0.6577222  0.6150769  0.58417845]] [[    53  36103     52  36104 101932]]\n"
     ]
    }
   ],
   "source": [
    "# Check that we can retrieve our random vector, search should be exact\n",
    "result_ip, result_indices = flat_index.search(\n",
    "    vector_in_index,\n",
    "    k\n",
    ")\n",
    "\n",
    "# Index 53 should be first with a IP value of 1\n",
    "print(result_ip, result_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29565a9b-9a3c-45e7-90b6-ffe327024bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0003568  0.6741253  0.65998363 0.62174714 0.5858568 ]] [[    53  36103     52  36104 101932]]\n"
     ]
    }
   ],
   "source": [
    "# Check that we can retrieve our random vector even with small noise added\n",
    "result_ip, result_indices = flat_index.search(\n",
    "    vector_in_index_with_noise,\n",
    "    k\n",
    ")\n",
    "\n",
    "# Index 53 should be first with a IP value of ~1\n",
    "print(result_ip, result_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffa1c306-6986-4aed-aa60-907319b0aa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes the FlatIndex 3.29s to run 500 random queries\n",
      "That's 0.007s per query\n"
     ]
    }
   ],
   "source": [
    "# Measure the speed of this solution\n",
    "time_for_queries = timeit.timeit(\n",
    "    lambda: flat_index.search(\n",
    "        np.random.random((1,dim)),\n",
    "        k\n",
    "    ), number = N_SEARCH_TIMEIT\n",
    ")\n",
    "\n",
    "print(f\"It takes the FlatIndex {time_for_queries:.2f}s to run {N_SEARCH_TIMEIT} random queries\")\n",
    "print(f\"That's {(time_for_queries / N_SEARCH_TIMEIT):.3f}s per query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf28ba3-07bd-4f73-819f-c673b76719f8",
   "metadata": {},
   "source": [
    "# Section 2: Two faster - but not exhaustive - methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cc367-f0cf-4c59-9245-185b1d2f2c17",
   "metadata": {},
   "source": [
    "## Inverted File Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0e57df-9262-41e2-8c00-fdd2e01d9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_voronoi_cells = 100\n",
    "n_voronoi_cells_visited_per_search = 3\n",
    "\n",
    "# Initialise the index, the FAISS package makes it super easy\n",
    "quantizer = faiss.IndexFlatIP(dim)\n",
    "ivf_index = faiss.IndexIVFFlat(quantizer, dim, n_voronoi_cells)\n",
    "\n",
    "# This simply finds the centroids to use\n",
    "assert not ivf_index.is_trained\n",
    "ivf_index.train(all_vectors[0:5000, :])\n",
    "assert ivf_index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2263d450-e232-4944-8fa7-b19d43afc199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually add the vectors in the structure\n",
    "ivf_index.add(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4de8aca1-2192-4794-ae0b-334994c3fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.65357697 0.68455553 0.7698461  0.83164287]] [[    53  36103     52  36104 101932]]\n"
     ]
    }
   ],
   "source": [
    "# Check that we can retrieve our random vector\n",
    "# For an exact vector match, we expect the query to be assigned\n",
    "# to the right centroid and hence always be returned\n",
    "result_distances, result_indices = ivf_index.search(\n",
    "    vector_in_index,\n",
    "    k,\n",
    "    params=faiss.SearchParametersIVF(\n",
    "        nprobe=n_voronoi_cells_visited_per_search\n",
    "    )\n",
    ")\n",
    "\n",
    "# now sure why but the index returns the distance instead of the IP value, so we expect 0 here\n",
    "print(result_distances, result_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "809a91d1-1915-4389-90ea-b4312e4102b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01200528 0.6644685  0.6927518  0.7692248  0.8410053 ]] [[    53  36103     52  36104 101932]]\n"
     ]
    }
   ],
   "source": [
    "# Check that we can retrieve our random vector\n",
    "# with some perturbation.\n",
    "# There's a chance the query lands in a different\n",
    "# centroid area and get missed...\n",
    "result_distances, result_indices = ivf_index.search(\n",
    "    vector_in_index_with_noise,\n",
    "    k,\n",
    "    params=faiss.SearchParametersIVF(\n",
    "        nprobe=n_voronoi_cells_visited_per_search\n",
    "    )\n",
    ")\n",
    "\n",
    "# ... but we still retrieve it here.\n",
    "print(result_distances, result_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20d1b924-71ac-4f3d-af22-3fd42f9d82c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes the IVFIndex 0.17s to run 500 random queries\n",
      "That's 0.00034s per query\n"
     ]
    }
   ],
   "source": [
    "time_for_queries = timeit.timeit(\n",
    "    lambda: ivf_index.search(\n",
    "        np.random.random((1,dim)),\n",
    "        k,\n",
    "        params=faiss.SearchParametersIVF(\n",
    "            nprobe=n_voronoi_cells_visited_per_search\n",
    "        )\n",
    "    ), number = N_SEARCH_TIMEIT\n",
    ")\n",
    "\n",
    "print(f\"It takes the IVFIndex {time_for_queries:.2f}s to run {N_SEARCH_TIMEIT} random queries\")\n",
    "print(f\"That's {(time_for_queries / N_SEARCH_TIMEIT):.5f}s per query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf0c76-9e97-4976-a68d-5c0c9b1e18d0",
   "metadata": {},
   "source": [
    "## HNSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0996b8ca-e014-4216-ac6b-b185ce8a36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the index, the FAISS package makes it super easy\n",
    "M = 16 # More info on M parameter: https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n",
    "efSearch = 10\n",
    "hnsw_index = faiss.IndexHNSWFlat(dim, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71794c1a-3f11-42b2-9791-4c9e697142de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually add the vectors in the structure, HNSW will take a little bit more time at construction time\n",
    "hnsw_index.add(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cac8bd6-626d-416f-a9be-2df4f8fabaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.65357697 0.68455553 0.7698461  0.8316429 ]] [[    53  36103     52  36104 101932]]\n"
     ]
    }
   ],
   "source": [
    "# Check that we can retrieve our random vector\n",
    "# Even for an exact vector match we're not certain\n",
    "# to retrieve our vector back...\n",
    "result_distances, result_indices = hnsw_index.search(\n",
    "    vector_in_index,\n",
    "    k,\n",
    "    params=faiss.SearchParametersHNSW(\n",
    "        efSearch=efSearch\n",
    "    )\n",
    ")\n",
    "\n",
    "# ... but we're still getting it here\n",
    "print(result_distances, result_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "581ceb50-796b-4174-9738-597886c96de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01200528 0.6644685  0.6927518  0.7692248  0.8410053 ]] [[    53  36103     52  36104 101932]]\n"
     ]
    }
   ],
   "source": [
    "# Check that we can retrieve our random distorted vector\n",
    "result_distances, result_indices = hnsw_index.search(\n",
    "    vector_in_index_with_noise,\n",
    "    k,\n",
    "    params=faiss.SearchParametersHNSW(\n",
    "        efSearch=efSearch\n",
    "    )\n",
    ")\n",
    "\n",
    "# ... same\n",
    "print(result_distances, result_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25485a12-e1a6-486a-a066-ca02e59120d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes the HNSWIndex 0.12s to run 500 random queries\n",
      "That's 0.00023s per query\n"
     ]
    }
   ],
   "source": [
    "time_for_queries = timeit.timeit(\n",
    "    lambda: hnsw_index.search(\n",
    "        np.random.random((1,dim)),\n",
    "        k,\n",
    "        params=faiss.SearchParametersHNSW(\n",
    "            efSearch=efSearch\n",
    "        )\n",
    "    ), number = N_SEARCH_TIMEIT\n",
    ")\n",
    "\n",
    "print(f\"It takes the HNSWIndex {time_for_queries:.2f}s to run {N_SEARCH_TIMEIT} random queries\")\n",
    "print(f\"That's {(time_for_queries / N_SEARCH_TIMEIT):.5f}s per query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f0276-9d6e-478b-9d35-8c898c623aec",
   "metadata": {},
   "source": [
    "# Section 3: How to evaluate the quality of our Approximate Nearest Neighbour search\n",
    "\n",
    "Broadly to tune our parameters, we want to make sure that we can retrieve some vectors in the\n",
    "index by querying the index with some of the exact same vectors, or with a few pertubations. (Index Recall)\n",
    "\n",
    "For IVF, we have 2 main parameters to tune:\n",
    "- the number of voronoi cells to create (creation time)\n",
    "- the number of voronoi cells to visit when querying (query time)\n",
    "\n",
    "For HNSW, we have 2 main params to tune as well (https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md):\n",
    "- M, which broadly reflects the density of links inter-nodes in the graph (creation time)\n",
    "- efSearch which correlates with the 'search depth' (query time)\n",
    "\n",
    "We can perform a grid search to optimise for recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c630053f-411c-4a22-93a2-9244434c53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(corpus_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "95ad02f4-15b0-4f90-bf35-e60dc36e20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test recall with n_voronoi_cells=100, n_voronoi_visits=1, we get:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.844"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_experiment_with_ivf_index(n_voronoi_cells: int, n_voronoi_visits: int, eps: float=0.0):\n",
    "    # Run a quick experiment with n_voronoi_cells / n_voronoi_visits params to figure\n",
    "    # out the index's recall with these parameters.\n",
    "    # We can also use eps to distort the query vectors\n",
    "    quantizer = faiss.IndexFlatIP(dim)\n",
    "    ivf_index = faiss.IndexIVFFlat(quantizer, dim, n_voronoi_cells)\n",
    "    ivf_index.train(all_vectors[0:10000, :])\n",
    "    assert ivf_index.is_trained\n",
    "\n",
    "    # Add vectors\n",
    "    ivf_index.add(all_vectors)\n",
    "        \n",
    "    N_QUERIES = 500\n",
    "    # pick a random vector from the dataset\n",
    "    rand_inds = np.random.randint([dataset_size] * N_QUERIES)\n",
    "    noise = eps * np.random.random((N_QUERIES, dim))\n",
    "    vectors_in_index_distorted = np.array(\n",
    "        corpus_dataset[rand_inds][\"embedding\"]\n",
    "    ) + noise\n",
    "\n",
    "    D,I = ivf_index.search(\n",
    "        vectors_in_index_distorted,\n",
    "        k,\n",
    "        params=faiss.SearchParametersIVF(\n",
    "            nprobe=n_voronoi_visits\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Returns the number of first retrieved index that match the original\n",
    "    num_matches = sum(I[:, 0]==rand_inds)\n",
    "\n",
    "    recall = num_matches / N_QUERIES\n",
    "    return recall \n",
    "\n",
    "# Test with on parameter pair\n",
    "print(\"Test recall with n_voronoi_cells=100, n_voronoi_visits=1, we get:\")\n",
    "run_experiment_with_ivf_index(\n",
    "    n_voronoi_cells=100,\n",
    "    n_voronoi_visits=1,\n",
    "    eps=0.1 # reasonable distortion\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f873776b-dbc8-411a-90c3-2baed41067f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▎                                                    | 2/6 [00:00<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- n_voronoi_cells=200, n_voronoi_visits=1 yields recall=0.792\n",
      "-- n_voronoi_cells=100, n_voronoi_visits=1 yields recall=0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████▌                                       | 3/6 [00:00<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- n_voronoi_cells=50, n_voronoi_visits=1 yields recall=0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████▋                          | 4/6 [00:00<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- n_voronoi_cells=200, n_voronoi_visits=3 yields recall=0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████▊             | 5/6 [00:01<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- n_voronoi_cells=100, n_voronoi_visits=3 yields recall=0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- n_voronoi_cells=50, n_voronoi_visits=3 yields recall=0.98\n",
      "Best params:\n",
      "best_n_voronoi_cells=50\n",
      "best_n_voronoi_visits=None\n",
      "yields:\n",
      "best_recall_so_far=0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall_so_far = -1\n",
    "best_n_voronoi_cells = None\n",
    "best_n_voronoi_visits = None\n",
    "\n",
    "# simple hand crafted grid search but you get the idea\n",
    "for n_voronoi_cells, n_voronoi_visits in tqdm([\n",
    "    (200, 1),\n",
    "    (100, 1),\n",
    "    (50, 1),\n",
    "    (200, 3),\n",
    "    (100, 3),\n",
    "    (50, 3),\n",
    "]):\n",
    "\n",
    "    new_recall = run_experiment_with_ivf_index(\n",
    "        n_voronoi_cells=n_voronoi_cells,\n",
    "        n_voronoi_visits=n_voronoi_visits,\n",
    "        eps=0.1 # reasonable distortion        \n",
    "    )\n",
    "    print(f\"-- n_voronoi_cells={n_voronoi_cells}, n_voronoi_visits={n_voronoi_visits} yields recall={new_recall}\")\n",
    "    if new_recall > best_recall_so_far:\n",
    "        best_recall_so_far = new_recall\n",
    "        best_n_voronoi_cells = n_voronoi_cells\n",
    "        best_n_voronoi_visits = best_n_voronoi_visits\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(f\"{best_n_voronoi_cells=}\")\n",
    "print(f\"{best_n_voronoi_visits=}\")\n",
    "\n",
    "print(\"yields:\")\n",
    "print(f\"{best_recall_so_far=}\")\n",
    "\n",
    "# Obviously you'd want to take into account processing time as well  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "472d4311-ea8d-4c10-975c-701cd19e6ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test recall with M=5, efSearch=5, we get:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_experiment_with_hnsw_index(M: int, efSearch: int, eps: float=0.0):\n",
    "    # Run a quick experiment with M / efSearch params to figure\n",
    "    # out the index's recall with these parameters.\n",
    "    # We can also use eps to distort the query vectors\n",
    "    hnsw_index = faiss.IndexHNSWFlat(dim, M)\n",
    "    hnsw_index.add(all_vectors)\n",
    "    \n",
    "    N_QUERIES = 500\n",
    "    # pick a random vector from the dataset\n",
    "    rand_inds = np.random.randint([dataset_size] * N_QUERIES)\n",
    "    noise = eps * np.random.random((N_QUERIES, dim))\n",
    "    vectors_in_index_distorted = np.array(\n",
    "        corpus_dataset[rand_inds][\"embedding\"]\n",
    "    ) + noise\n",
    "\n",
    "    D,I = hnsw_index.search(\n",
    "        vectors_in_index_distorted,\n",
    "        k,\n",
    "        params=faiss.SearchParametersHNSW(\n",
    "            efSearch=efSearch\n",
    "        )\n",
    "    )\n",
    "    # Returns the number of first retrieved index that match the original\n",
    "    num_matches = sum(I[:, 0]==rand_inds)\n",
    "\n",
    "    recall = num_matches / N_QUERIES\n",
    "    return recall \n",
    "\n",
    "# Test with on parameter pair\n",
    "print(\"Test recall with M=5, efSearch=5, we get:\")\n",
    "run_experiment_with_hnsw_index(\n",
    "    M=5,\n",
    "    efSearch=5,\n",
    "    eps=0.1 # reasonable distortion\n",
    ")\n",
    "# 50% is not great! Hence there's value in optimising our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aba758c7-c422-421c-90c3-f77afb5534ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▏                                                                 | 1/6 [00:04<00:20,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- M=10, efSearch=10 yields recall=0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▎                                                    | 2/6 [00:08<00:17,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- M=20, efSearch=10 yields recall=0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████▌                                       | 3/6 [00:17<00:18,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- M=40, efSearch=10 yields recall=0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████▋                          | 4/6 [00:21<00:10,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- M=10, efSearch=20 yields recall=0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████▊             | 5/6 [00:26<00:05,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- M=20, efSearch=20 yields recall=0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 6/6 [00:34<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- M=40, efSearch=20 yields recall=0.986\n",
      "Best params:\n",
      "best_n_voronoi_cells=50\n",
      "best_n_voronoi_visits=None\n",
      "yields:\n",
      "best_recall_so_far=0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_recall_so_far = -1\n",
    "best_n_voronoi_cells = None\n",
    "best_n_voronoi_visits = None\n",
    "\n",
    "# simple hand crafted grid search but you get the idea\n",
    "for M, efSearch in tqdm([\n",
    "    (10, 10),\n",
    "    (20, 10),\n",
    "    (40, 10),\n",
    "    (10, 20),\n",
    "    (20, 20),\n",
    "    (40, 20),\n",
    "]):\n",
    "\n",
    "    new_recall = run_experiment_with_hnsw_index(\n",
    "        M=M,\n",
    "        efSearch=efSearch,\n",
    "        eps=0.1 # reasonable distortion        \n",
    "    )\n",
    "    print(f\"-- M={M}, efSearch={efSearch} yields recall={new_recall}\")\n",
    "    if new_recall > best_recall_so_far:\n",
    "        best_recall_so_far = new_recall\n",
    "        best_n_voronoi_cells = n_voronoi_cells\n",
    "        best_n_voronoi_visits = best_n_voronoi_visits\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(f\"{best_n_voronoi_cells=}\")\n",
    "print(f\"{best_n_voronoi_visits=}\")\n",
    "\n",
    "print(\"yields:\")\n",
    "print(f\"{best_recall_so_far=}\")\n",
    "\n",
    "# Obviously you'd want to take into account processing time as well, shown in TQDM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146147a-b80f-4bb1-9638-5487329f762c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
